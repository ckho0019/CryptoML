{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUdrKjcXDDmd",
        "outputId": "411b83cc-a5a0-40b2-d566-6fb3aae73a6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OO2fAyuDFRL",
        "outputId": "ff92d8db-7f01-4d7e-d221-9aaf00de5b51"
      },
      "source": [
        "# MODIFY HERE TO YOUR PATH IN GOOGLE DRIVE\n",
        "%cd /content/gdrive/MyDrive/CryptoML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CryptoML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhpoMEFWXywa"
      },
      "source": [
        "import speck as sp\n",
        "import numpy as np\n",
        "from pickle import dump\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "bs = 5000;\n",
        "dir = './models/'\n",
        "\n",
        "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
        "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
        "  return(res);\n",
        "\n",
        "def make_checkpoint(datei):\n",
        "  res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True);\n",
        "  return(res);\n",
        "\n",
        "# make residual tower of convolutional blocks\n",
        "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3, depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
        "  # Input and preprocessing layers\n",
        "  inp = Input(shape=(num_blocks * word_size * 2))\n",
        "  rs = Reshape((2 * num_blocks, word_size))(inp)\n",
        "  perm = Permute((2,1))(rs)\n",
        "  \n",
        "  # add a single residual layer that will expand the data to num_filters channels\n",
        "  # this is a bit-sliced layer\n",
        "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm)\n",
        "  conv0 = BatchNormalization()(conv0)\n",
        "  conv0 = Activation('relu')(conv0)\n",
        "\n",
        "  # add residual blocks\n",
        "  shortcut = conv0\n",
        "  for _ in range(depth):\n",
        "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    shortcut = Add()([shortcut, conv2])\n",
        "\n",
        "  # add prediction head\n",
        "  flat1 = Flatten()(shortcut)\n",
        "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1)\n",
        "  dense1 = BatchNormalization()(dense1)\n",
        "  dense1 = Activation('relu')(dense1)\n",
        "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1)\n",
        "  dense2 = BatchNormalization()(dense2)\n",
        "  dense2 = Activation('relu')(dense2)\n",
        "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2)\n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_speck_distinguisher(num_epochs, num_rounds=7, depth=1, num_blocks=2, diffa=(0x0040,0), diffb=(0x0020,0)):\n",
        "    # create the network\n",
        "    net = make_resnet(num_blocks=num_blocks, depth=depth, reg_param=10**-5)\n",
        "    net.compile(optimizer='adam',loss='mse',metrics=['acc'])\n",
        "\n",
        "    # generate training and validation data\n",
        "    if num_blocks == 2:\n",
        "      X, Y = sp.make_train_data_2pt(10**7, num_rounds, diff=diffa)\n",
        "      X_eval, Y_eval = sp.make_train_data_2pt(10**6, num_rounds, diff=diffa)\n",
        "    \n",
        "    else:\n",
        "      X, Y = sp.make_train_data_4pt(10**7, num_rounds, diffa=diffa, diffb=diffb)\n",
        "      X_eval, Y_eval = sp.make_train_data_4pt(10**6, num_rounds, diffa=diffa, diffb=diffb)\n",
        "\n",
        "    # set up model checkpoint\n",
        "    check = make_checkpoint(dir+'best'+str(num_rounds)+'depth'+str(depth)+'.h5')\n",
        "\n",
        "    # create learnrate schedule\n",
        "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001))\n",
        "\n",
        "    # train and evaluate\n",
        "    h = net.fit(X,Y,epochs=num_epochs,batch_size=bs,validation_data=(X_eval, Y_eval), callbacks=[lr,check])\n",
        "    np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_acc'])\n",
        "    np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_loss'])\n",
        "    dump(h.history,open(dir+'hist'+str(num_rounds)+'r_depth'+str(depth)+'.p','wb'))\n",
        "    print(\"Best validation accuracy: \", np.max(h.history['val_acc']))\n",
        "\n",
        "    return net, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kX49J7fDx4-"
      },
      "source": [
        "# MODIFY HERE: \n",
        "\n",
        "# number of epochs, number of Speck rounds, depth, number of plaintexts (2 or 4), bit difference #1, bit difference #2 (if 4 plaintexts)\n",
        "train_speck_distinguisher(1, num_rounds=5, depth=10, num_blocks=4, diffa=(0x0040,0), diffb=(0x0020,0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}